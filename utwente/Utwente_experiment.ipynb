{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Utwente_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--cDX0m4Clb8",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnmtWv8lClb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG6zLeKhClcA",
        "colab_type": "code",
        "outputId": "fbb7b9a1-b36f-437c-ecb8-07afc8317254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "act_labels = np.array([\"walk\", \"stand\", \"jog\", \"sit\", \"bike\", \"ups\", \"downs\",\n",
        "                       \"type\", \"write\", \"coffee\", \"talk\", \"smoke\", \"eat\"])\n",
        "\n",
        "columns_labels = np.array([\"timeStamp\", \"accX\", \"accY\", \"accZ\", \"linX\", \"linY\",\"linZ\",\n",
        "                           \"gyrX\", \"gyrY\", \"gyrZ\", \"magX\", \"magY\", \"magZ\", \"actLabel\"])\n",
        "\n",
        "\n",
        "wrist = pd.DataFrame(columns = columns_labels)\n",
        "tmp = pd.read_csv(\"smartphoneatwrist.csv\", header=None)\n",
        "tmp.columns = columns_labels\n",
        "wrist = wrist.append(tmp)\n",
        "\n",
        "wrist = wrist.drop(columns=['timeStamp'])\n",
        "\n",
        "wrist['actLabel'] -= 11111\n",
        "\n",
        "print(wrist.shape)\n",
        "print([(i,v) for i, v in enumerate(act_labels)])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1170000, 13)\n",
            "[(0, 'walk'), (1, 'stand'), (2, 'jog'), (3, 'sit'), (4, 'bike'), (5, 'ups'), (6, 'downs'), (7, 'type'), (8, 'write'), (9, 'coffee'), (10, 'talk'), (11, 'smoke'), (12, 'eat')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D8K27OiSV9j",
        "colab_type": "code",
        "outputId": "cdb6aab0-e360-4ef2-878b-4b00776dd8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "act_labels = np.array([\"walk\", \"stand\", \"jog\", \"sit\", \"bike\", \"ups\", \"downs\",\n",
        "                       \"type\", \"write\", \"coffee\", \"talk\", \"smoke\", \"eat\"])\n",
        "\n",
        "sensors = [\"accX\", \"accY\", \"accZ\", \"gyrX\", \"gyrY\", \"gyrZ\",\"magX\", \"magY\", \"magZ\"]\n",
        "sensors.append(\"actLabel\")\n",
        "red_act_labels = np.array([\"walk\", \"stand\", \"jog\", \"sit\", \"bike\", \"ups\", \"downs\",\n",
        "                       \"type\", \"write\", \"smoke\", \"eat\"])\n",
        "# red_act_labels = act_labels\n",
        "activites = [i for i, x in enumerate(act_labels) if x in red_act_labels]\n",
        "activites"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uPAtKXYSawh",
        "colab_type": "code",
        "outputId": "7e93bb62-3b63-41e3-e1e2-5c4b7a125692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "wrist  = wrist[wrist[\"actLabel\"].isin(activites)][sensors]\n",
        "wrist[\"actLabel\"] = wrist[\"actLabel\"].astype(\"category\").cat.codes\n",
        "\n",
        "tmp = wrist[\"actLabel\"].values\n",
        "tmp[tmp==11] = 9\n",
        "tmp[tmp==12] = 10\n",
        "wrist[\"actLabel\"] = tmp\n",
        "\n",
        "for i in zip(wrist.actLabel.unique(), red_act_labels):\n",
        "  print(i)\n",
        "  \n",
        "wrist.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 'walk')\n",
            "(1, 'stand')\n",
            "(2, 'jog')\n",
            "(3, 'sit')\n",
            "(4, 'bike')\n",
            "(5, 'ups')\n",
            "(6, 'downs')\n",
            "(7, 'type')\n",
            "(8, 'write')\n",
            "(9, 'smoke')\n",
            "(10, 'eat')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(990000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCBaJvCwClcF",
        "colab_type": "text"
      },
      "source": [
        "### Making Training _ Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Swj1uyzClcG",
        "colab_type": "code",
        "outputId": "c200f73d-0b0e-4355-ac22-d74bd39989be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "columns_labels = sensors\n",
        "wrist_train_ts = pd.DataFrame(columns = columns_labels)\n",
        "wrist_test_ts = pd.DataFrame(columns = columns_labels)\n",
        "\n",
        "\n",
        "train_test_ratio = .80\n",
        "segment = 5\n",
        "start = 0\n",
        "step = (int)(((len(wrist)//len(act_labels) ) // segment))\n",
        "end = step\n",
        "cut = (int)(train_test_ratio*(end-start))\n",
        "for i,_ in enumerate(act_labels):\n",
        "    for j in range(segment):        \n",
        "        wrist_train_ts = wrist_train_ts.append(wrist[start:cut])  \n",
        "        wrist_test_ts = wrist_test_ts.append(wrist[cut:end]) \n",
        "\n",
        "        start = end\n",
        "        end += step\n",
        "        cut = start+(int)(train_test_ratio*(end-start))\n",
        "        \n",
        "wrist_train_ts.shape, wrist_test_ts.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((791960, 10), (197990, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yGzeCwAPXE72"
      },
      "source": [
        "### Running Sliding Window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHLY89iYClcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ts_to_secs(values, w, s, standardize = False, **options):\n",
        "    \n",
        "    data = values[:,:values.shape[1]-1]    \n",
        "    act_labels = values[:,values.shape[1]-1]\n",
        "    mean = 0\n",
        "    std = 1\n",
        "    \n",
        "    data = np.array(data, dtype=np.float64)\n",
        "\n",
        "    if standardize:\n",
        "        ## Standardize each sensorâ€™s data to have a zero mean and unity standard deviation.\n",
        "        ## As usual, we normalize test dataset by training dataset's parameters \n",
        "        if options:\n",
        "            mean = options.get(\"mean\")\n",
        "            std = options.get(\"std\")\n",
        "            print(\"[INFO] -- Test Data has been standardized\")\n",
        "        else:\n",
        "            mean = data.mean(axis=0)\n",
        "            std = np.std(data, axis=0)\n",
        "            print(\"[INFO] -- Training Data has been standardized: the mean is = \"+str(mean)+\" ; and the std is = \"+str(std))            \n",
        "\n",
        "        data -= mean\n",
        "        data /= std\n",
        "    else:\n",
        "        print(\"[INFO] -- Without Standardization.....\")\n",
        "\n",
        "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
        "    data = data.T\n",
        "\n",
        "    m = data.shape[0]   # Data Dimension \n",
        "    ttp = data.shape[1] # Total Time Points\n",
        "    number_of_secs = int(round(((ttp - w)/s)))\n",
        "\n",
        "    ##  Create a 3D matrix for Storing Sections  \n",
        "    secs_data = np.zeros((number_of_secs , m , w ))\n",
        "    act_secs_labels = np.zeros(number_of_secs)\n",
        "\n",
        "    k=0\n",
        "    for i in range(0 , ttp-w, s):\n",
        "        j = i // s\n",
        "        if j >= number_of_secs:\n",
        "            break\n",
        "\n",
        "        if act_labels[i] != act_labels[i+w-1]: \n",
        "            continue\n",
        "            \n",
        "        secs_data[k] = data[:, i:i+w]\n",
        "        act_secs_labels[k] = act_labels[i]\n",
        "        k = k+1\n",
        "        \n",
        "    secs_data = secs_data[0:k]\n",
        "    act_secs_labels = act_secs_labels[0:k]\n",
        "    return secs_data, act_secs_labels, mean, std\n",
        "##________________________________________________________________"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ta4vb8sClcQ",
        "colab_type": "code",
        "outputId": "a0c97919-f29c-44e6-e88e-4d31c4a70b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "w = 100\n",
        "s = 10\n",
        "wrist_train_data, wrist_act_train, wrist_train_mean, wrist_train_std = ts_to_secs(wrist_train_ts.values.copy(),\n",
        "                                                                   w,\n",
        "                                                                   s,\n",
        "                                                                   standardize = True)\n",
        "\n",
        "s = 25\n",
        "wrist_test_data, wrist_act_test, _, _ = ts_to_secs(wrist_test_ts.values.copy(),\n",
        "                                                              w,\n",
        "                                                              s,\n",
        "                                                              standardize = True,\n",
        "                                                              mean = wrist_train_mean, \n",
        "                                                              std = wrist_train_std)\n",
        "\n",
        "print(\"Shape of wrist_train_data: \"+str(wrist_train_data.shape))\n",
        "print(\"Shape of wrist_test_data:  \"+str(wrist_test_data.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] -- Training Data has been standardized: the mean is = [ 4.91083713e+00 -4.31141898e+00 -3.56024941e+00 -1.55568460e-02\n",
            "  1.92573487e-02  9.43957687e-03 -1.38038766e+01  1.37777186e+01\n",
            "  1.60786221e+01] ; and the std is = [ 3.85822703  5.91729175  3.81122627  0.78177491  0.82447662  1.15599653\n",
            " 22.55622994 21.91590316 23.0503767 ]\n",
            "[INFO] -- Test Data has been standardized\n",
            "Shape of wrist_train_data: (79087, 9, 100)\n",
            "Shape of wrist_test_data:  (7876, 9, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwbbfAYNClcS",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpyoWVfNClcT",
        "colab_type": "code",
        "outputId": "346ba7e3-f81e-46e5-897f-a983c4a8e01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "import keras \n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from collections import Counter\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.layers import Reshape\n",
        "from keras.models import Sequential, Model, load_model, model_from_json \n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, Flatten, Reshape, Concatenate,  Dropout , LSTM, TimeDistributed, RepeatVector\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, ConvLSTM2D, Conv3D, MaxPooling3D, Conv3DTranspose\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLn_UGjeClcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Estimator:\n",
        "    l2p = 0.0001\n",
        "    @staticmethod\n",
        "    def early_layers(inp, fm, hid_act_func=\"relu\"):\n",
        "        # Start\n",
        "        x = Conv2D(256, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
        "        x = Dropout(0.25)(x)\n",
        "        \n",
        "        # 1\n",
        "        x = Conv2D(128, fm, padding=\"same\", kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
        "        x = Dropout(0.25)(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def late_layers(inp, num_classes, fm, act_func=\"softmax\", hid_act_func=\"relu\", b_name=\"Identifier\"):\n",
        "        # 2\n",
        "        x = Conv2D(128, (1,5), padding=\"same\", strides= (1,1), kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(inp)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
        "        x = Dropout(0.25)(x)\n",
        "        \n",
        "        # 2\n",
        "        x = Conv2D(128, (1,5), padding=\"same\", strides= (3,1), kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
        "        x = Dropout(0.25)(x)\n",
        "        \n",
        "        # End\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(256, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(64, kernel_regularizer=regularizers.l2(Estimator.l2p), activation=hid_act_func)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(num_classes, activation=act_func, name = b_name)(x)\n",
        "\n",
        "        return x\n",
        "   \n",
        "    @staticmethod\n",
        "    def build(height, width, num_classes, name, fm, act_func=\"softmax\",hid_act_func=\"relu\"):\n",
        "        inp = Input(shape=(height, width, 1))\n",
        "        early = Estimator.early_layers(inp, fm, hid_act_func=hid_act_func)\n",
        "        late  = Estimator.late_layers(early, num_classes, fm, act_func=act_func, hid_act_func=hid_act_func)\n",
        "        model = Model(inputs=inp, outputs=late ,name=name)\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgUpPOOmClcY",
        "colab_type": "code",
        "outputId": "f6a0679c-3c6d-4f8e-e45c-b54c15c576e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "## Here we add an extra dimension to the datasets just to be ready for using with Convolution2D\n",
        "wrist_train_data = np.expand_dims(wrist_train_data,axis=3)\n",
        "print(\"[INFO] -- Shape of wrist_train_data:\", wrist_train_data.shape)\n",
        "wrist_test_data = np.expand_dims(wrist_test_data,axis=3)\n",
        "print(\"[INFO] -- Shape of wrist_test_data\", wrist_test_data.shape)\n",
        "\n",
        "wrist_act_train_labels = to_categorical(wrist_act_train)\n",
        "wrist_act_test_labels = to_categorical(wrist_act_test)\n",
        "wrist_act_train_labels.shape, wrist_act_test_labels.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] -- Shape of wrist_train_data: (79087, 9, 100, 1)\n",
            "[INFO] -- Shape of wrist_test_data (7876, 9, 100, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((79087, 11), (7876, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ZY0b5x0DZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_results(M, X, Y, position):\n",
        "    result1 = M.evaluate(X, Y, verbose = 2)\n",
        "    act_acc = result1[1].round(4)*100\n",
        "    print(\"***[RESULT]*** \"+position+\" ACT Accuracy: \"+str(act_acc))\n",
        "\n",
        "    preds = M.predict(X)\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    conf_mat = confusion_matrix(np.argmax(Y, axis=1), preds)\n",
        "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "    print(\"***[RESULT]*** \"+position+\" ACT  Confusion Matrix\")\n",
        "    print(\" | \".join(red_act_labels))\n",
        "    print(np.array(conf_mat).round(3)*100)  \n",
        "\n",
        "    f1act = f1_score(np.argmax(Y, axis=1), preds, average=None).mean()\n",
        "    print(\"***[RESULT]*** \"+position+\" ACT Averaged F-1 Score : \"+str(f1act*100))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgKZV3LiClcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def eval_act(X,Y, Xt, Yt, act_class_numbers, fm, ep=50, position = \"wrist\"):\n",
        "    height = X.shape[1]\n",
        "    width = X.shape[2]\n",
        "    ## Callbacks\n",
        "    eval_metric= \"val_acc\"    \n",
        "    #eval_metric = \"acc\"\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor = eval_metric, mode = 'max', patience = 20)\n",
        "    filepath=position+\".hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor=eval_metric, verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [early_stop,checkpoint]\n",
        "    \n",
        "    eval_act = Estimator.build(height, width, act_class_numbers, name =\"EVAL_ACT\", fm=fm, act_func=\"softmax\",hid_act_func=\"relu\")\n",
        "    eval_act.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc'])\n",
        "    X , Y = shuffle(X,Y)\n",
        "    print(eval_act.summary())\n",
        "\n",
        "## Uncomment this to train your own Classifier model\n",
        "#     eval_act.fit(X, Y,\n",
        "#                 validation_data = (Xt,Yt),\n",
        "#                 epochs = ep,\n",
        "#                 batch_size = 128,\n",
        "#                 verbose = 2,\n",
        "#                 callbacks = callbacks_list\n",
        "#                )\n",
        "\n",
        "    eval_act.load_weights(position+\".hdf5\")\n",
        "    eval_act.compile( loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc'])\n",
        "    \n",
        "    print_results(eval_act, X, Y, position)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3OYa8LQ2RBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "636e740d-b779-4eb7-a023-67e1abe8b10e"
      },
      "source": [
        "print(\"Training on Raw Data:\")\n",
        "eval_act(wrist_train_data.copy(), wrist_act_train_labels.copy(),\n",
        "         wrist_test_data.copy(), wrist_act_test_labels.copy(),\n",
        "         len(red_act_labels), fm = (3,5), position = \"Classifier_model\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on Raw Data:\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"EVAL_ACT\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 9, 100, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 100, 256)       4096      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 9, 100, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 9, 50, 256)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 50, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 50, 128)        491648    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 9, 50, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 25, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 25, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 25, 128)        82048     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 9, 25, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 9, 12, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 9, 12, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 12, 128)        82048     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 3, 12, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "Identifier (Dense)           (None, 11)                715       \n",
            "=================================================================\n",
            "Total params: 1,270,923\n",
            "Trainable params: 1,269,003\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "***[RESULT]*** Classifier_model ACT Accuracy: 99.9\n",
            "***[RESULT]*** Classifier_model ACT  Confusion Matrix\n",
            "walk | stand | jog | sit | bike | ups | downs | type | write | smoke | eat\n",
            "[[ 99.8   0.    0.    0.    0.    0.    0.2   0.    0.    0.    0. ]\n",
            " [  0.   99.9   0.    0.    0.    0.    0.    0.    0.    0.1   0. ]\n",
            " [  0.    0.  100.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.  100.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.  100.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.1   0.    0.    0.    0.   99.9   0.    0.    0.    0.    0. ]\n",
            " [  0.    0.1   0.    0.    0.    0.   99.8   0.    0.    0.1   0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.  100.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.  100.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.   99.5   0.5]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  100. ]]\n",
            "***[RESULT]*** Classifier_model ACT Averaged F-1 Score : 99.89628800033852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "repZSB5vW0vq",
        "colab_type": "code",
        "outputId": "221e6420-0d8c-40be-c305-5b50844df2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(\"Inference on Raw Data:\")\n",
        "from keras.models import load_model\n",
        "eval_act = load_model(\"Classifier_model.hdf5\")\n",
        "\n",
        "X = wrist_test_data\n",
        "Y = wrist_act_test_labels\n",
        "\n",
        "print_results(eval_act, X, Y, \"Classifier_model\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference on Raw Data:\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "***[RESULT]*** Classifier_model ACT Accuracy: 99.19\n",
            "***[RESULT]*** Classifier_model ACT  Confusion Matrix\n",
            "walk | stand | jog | sit | bike | ups | downs | type | write | smoke | eat\n",
            "[[ 97.5   0.    0.    0.    0.    0.7   1.5   0.    0.    0.3   0. ]\n",
            " [  0.   99.4   0.    0.    0.    0.    0.    0.    0.    0.6   0. ]\n",
            " [  0.    0.  100.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.   98.6   0.    0.    0.    1.    0.1   0.1   0.1]\n",
            " [  0.    0.    0.    0.  100.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.4   0.1   0.4   0.    0.   98.8   0.    0.    0.    0.3   0. ]\n",
            " [  0.    0.    0.    0.    0.    0.3  99.7   0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.  100.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.   99.9   0.    0.1]\n",
            " [  0.    0.    0.    0.1   0.    0.    0.    0.    0.   97.5   2.3]\n",
            " [  0.    0.3   0.    0.    0.    0.    0.    0.    0.    0.1  99.6]]\n",
            "***[RESULT]*** Classifier_model ACT Averaged F-1 Score : 99.18475840173063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ65jUTFClcg",
        "colab_type": "text"
      },
      "source": [
        "# Replacement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88THIvt4Clch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = wrist_train_data\n",
        "test_data = wrist_test_data\n",
        "act_train = wrist_act_train\n",
        "act_test = wrist_act_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kla-IavP-0zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.expand_dims(train_data, axis=1)\n",
        "test_data = np.expand_dims(test_data, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrlHYytoClci",
        "colab_type": "code",
        "outputId": "8c96ec3e-e7b9-4c4c-95ca-610dc9cbeb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "for i,v in enumerate(red_act_labels):\n",
        "  print(i,v)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 walk\n",
            "1 stand\n",
            "2 jog\n",
            "3 sit\n",
            "4 bike\n",
            "5 ups\n",
            "6 downs\n",
            "7 type\n",
            "8 write\n",
            "9 smoke\n",
            "10 eat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8a9bcsDClcl",
        "colab_type": "code",
        "outputId": "1ff2de63-0de5-4338-ac5c-d17fd653f76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(\"White Listed\", end=\"--> \")\n",
        "wl = [0,2,4,5,6]\n",
        "for i in wl:\n",
        "    print(red_act_labels[i], end=\"; \")\n",
        "\n",
        "print(\"\\nGray Listed\", end=\" --> \")\n",
        "gl = [1,3]\n",
        "for i in gl:\n",
        "    print(red_act_labels[i], end=\"; \")\n",
        "\n",
        "bl = [7, 8, 9,10]\n",
        "print(\"\\nBlack Listed\", end=\"--> \")\n",
        "for i in bl:\n",
        "    print(red_act_labels[i], end=\"; \")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "White Listed--> walk; jog; bike; ups; downs; \n",
            "Gray Listed --> stand; sit; \n",
            "Black Listed--> type; write; smoke; eat; "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV-9Eew41DCV",
        "colab_type": "code",
        "outputId": "5fa209dc-678b-4a48-c7a6-5caf6d9e1566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "w_train_data = train_data[np.isin(act_train,wl)]\n",
        "g_train_data = train_data[np.isin(act_train,gl)]\n",
        "b_train_data = train_data[np.isin(act_train,bl)]\n",
        "print(\"[INFO] -- Shape of Train Whites :\"+str(w_train_data.shape))\n",
        "print(\"[INFO] -- Shape of Train Grays :\"+str(g_train_data.shape))\n",
        "print(\"[INFO] -- Shape of Train Blacks :\"+str(b_train_data.shape))\n",
        "\n",
        "w_test_data = test_data[np.isin(act_test,wl)]\n",
        "g_test_data = test_data[np.isin(act_test,gl)]\n",
        "b_test_data = test_data[np.isin(act_test,bl)]\n",
        "print(\"[INFO] -- Shape of Train Whites :\"+str(w_test_data.shape))\n",
        "print(\"[INFO] -- Shape of Train Grays :\"+str(g_test_data.shape))\n",
        "print(\"[INFO] -- Shape of Train Blacks :\"+str(b_test_data.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] -- Shape of Train Whites :(35980, 1, 9, 100, 1)\n",
            "[INFO] -- Shape of Train Grays :(14463, 1, 9, 100, 1)\n",
            "[INFO] -- Shape of Train Blacks :(28644, 1, 9, 100, 1)\n",
            "[INFO] -- Shape of Train Whites :(3569, 1, 9, 100, 1)\n",
            "[INFO] -- Shape of Train Grays :(1399, 1, 9, 100, 1)\n",
            "[INFO] -- Shape of Train Blacks :(2908, 1, 9, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lA54lxgu1yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_of_epochs = 50\n",
        "\n",
        "rnd_idx_train = np.random.choice(g_train_data.shape[0], b_train_data.shape[0], replace=True)\n",
        "tmp =  g_train_data[rnd_idx_train,:]\n",
        "b_train_transformed = tmp.copy()\n",
        "\n",
        "x_train = np.append(w_train_data, g_train_data, axis=0)\n",
        "x_train = np.append(x_train, b_train_data, axis=0)\n",
        "\n",
        "x_train_transformed = np.append(w_train_data, g_train_data, axis=0)\n",
        "x_train_transformed = np.append(x_train_transformed , b_train_transformed, axis=0)\n",
        "\n",
        "resh = np.prod(w_train_data.shape[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoaqROgk2x6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "90f947d7-f0fa-4151-97ce-51818c4d2470"
      },
      "source": [
        "filepath=\"RAE_model.hdf5\"\n",
        "\n",
        "w = 100; prs = 1; sens = 3; chns = 3 ; num_classes = 11\n",
        "\n",
        "inp = Input(shape=(prs, sens*chns, w,1))\n",
        "x = ConvLSTM2D(128,  kernel_size=(3, 5), strides=(1,1), padding='same', \n",
        "               return_sequences=True)(inp)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = ConvLSTM2D(64,  kernel_size=(3, 5), strides=(1,1), padding='same', \n",
        "               return_sequences=True)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv3DTranspose(64, (3,5,1), padding=\"same\", activation='selu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv3DTranspose(128, (3,5,1), padding=\"same\", activation='selu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv3DTranspose(1, (3,5,1), padding=\"same\", activation='linear')(x)\n",
        "\n",
        "raet = Model(inputs=inp, outputs=x ,name=\"REPConvLSTM2D\")\n",
        "\n",
        "print(raet.summary())\n",
        "\n",
        "eval_metric= \"loss\"    \n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = eval_metric, mode = 'min', patience = 20)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=eval_metric, verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [early_stop,checkpoint]\n",
        "\n",
        "raet.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# x_train, x_train_transformed = shuffle(x_train, x_train_transformed)\n",
        "\n",
        "## Uncomment this to train your own RAE model\n",
        "# raet.fit(x_train , x_train_transformed,\n",
        "#                 #validation_split = 0.1,\n",
        "#                 epochs = num_of_epochs,\n",
        "#                 batch_size = batch_size,\n",
        "#                 shuffle = True,\n",
        "#                 verbose = 1,\n",
        "#                 callbacks = callbacks_list\n",
        "#                 )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"REPConvLSTM2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1, 9, 100, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 1, 9, 100, 128)    991232    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 9, 100, 128)    512       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 1, 9, 100, 64)     737536    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1, 9, 100, 64)     256       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_1 (Conv3DTr (None, 1, 9, 100, 64)     61504     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1, 9, 100, 64)     256       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_2 (Conv3DTr (None, 1, 9, 100, 128)    123008    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 1, 9, 100, 128)    512       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_3 (Conv3DTr (None, 1, 9, 100, 1)      1921      \n",
            "=================================================================\n",
            "Total params: 1,916,737\n",
            "Trainable params: 1,915,969\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78MxVNf84GkX",
        "colab_type": "code",
        "outputId": "33888bd3-281f-48a6-c469-a6358d68d012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(\"Results after Transformation\")\n",
        "act_test_labels = to_categorical(act_test)\n",
        "\n",
        "rae = load_model(\"RAE_model.hdf5\")\n",
        "\n",
        "rep_x_test = test_data.copy()\n",
        "rep_x_test = rae.predict(rep_x_test, verbose=1)\n",
        "\n",
        "from keras.models import load_model\n",
        "eval_act = load_model(\"Classifier_model.hdf5\")\n",
        "X = rep_x_test[:,0,:,:,:]\n",
        "Y = act_test_labels\n",
        "print_results(eval_act, X, Y, \"Classifier_model\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after Transformation\n",
            "7876/7876 [==============================] - 26s 3ms/step\n",
            "***[RESULT]*** Classifier_model ACT Accuracy: 62.71\n",
            "***[RESULT]*** Classifier_model ACT  Confusion Matrix\n",
            "walk | stand | jog | sit | bike | ups | downs | type | write | smoke | eat\n",
            "[[ 97.2   0.    0.    0.    0.    0.7   1.9   0.    0.    0.1   0. ]\n",
            " [  0.   98.2   0.    0.    0.3   0.    0.    0.    0.    1.5   0. ]\n",
            " [  0.    0.  100.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.   96.8   0.3   0.    0.    0.    0.1   2.8   0. ]\n",
            " [  0.    0.    0.    0.  100.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.3   0.1   0.4   0.    0.1  98.8   0.    0.    0.    0.3   0. ]\n",
            " [  0.    0.    0.    0.    0.    0.3  99.7   0.    0.    0.    0. ]\n",
            " [  0.    0.    0.  100.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.   99.3   0.7   0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.   94.9   0.1   0.    0.    0.    0.    5.    0. ]\n",
            " [  0.    0.    0.   99.4   0.4   0.    0.    0.    0.    0.1   0. ]]\n",
            "***[RESULT]*** Classifier_model ACT Averaged F-1 Score : 57.81683062335158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}